{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "image_pixels = 784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cre_weights(shape):\n",
    "    #shape =[Image pixels,layer_unit]\n",
    "    init = tf.truncated_normal(shape=shape,stddev=1.0 /math.sqrt(float(shape[0])))#???\n",
    "    return tf.Variable(init,name='weights')\n",
    "def cre_biases(shape):\n",
    "    #shape=[layer_unit]\n",
    "    init = tf.zeros(shape)\n",
    "    return tf.Variable(init,name='biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_36:0\", shape=(100, 100), dtype=float32)\n",
      "WARNING:tensorflow:From /home/liunian/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "2.1080887\n",
      "1.8854516\n",
      "1.7058508\n",
      "1.6954466\n",
      "1.5841569\n",
      "1.7222083\n",
      "1.4580173\n",
      "1.6614273\n",
      "1.3435466\n",
      "1.3357925\n",
      "1.3246132\n",
      "1.3352747\n",
      "1.2227576\n",
      "1.2210734\n",
      "1.3065083\n",
      "1.4224226\n",
      "1.3023684\n",
      "1.40103\n",
      "1.2662997\n",
      "1.2418957\n",
      "1.144901\n",
      "1.2395594\n",
      "1.1582154\n",
      "1.1758407\n",
      "1.2035064\n",
      "1.3048546\n",
      "1.285868\n",
      "1.163743\n",
      "1.3524969\n",
      "1.1406729\n",
      "1.2579186\n",
      "1.1209096\n",
      "1.0901847\n",
      "1.1755126\n",
      "1.2638001\n",
      "1.1243472\n",
      "1.0670826\n",
      "1.1778728\n",
      "1.1299605\n",
      "1.0750326\n",
      "1.1753548\n",
      "1.2060536\n",
      "1.454515\n",
      "1.2480488\n",
      "1.0815847\n",
      "0.99293184\n",
      "1.0562847\n",
      "1.1320767\n",
      "1.1934242\n",
      "1.1150341\n",
      "1.1271882\n",
      "1.2101114\n",
      "1.0793779\n",
      "1.2282128\n",
      "1.2322379\n",
      "0.957849\n",
      "0.9752778\n",
      "1.1198778\n",
      "1.1583202\n",
      "1.0896733\n",
      "0.94903386\n",
      "1.1625533\n",
      "0.9310215\n",
      "1.2714874\n",
      "1.0196936\n",
      "0.9254494\n",
      "1.1640422\n",
      "1.1336573\n",
      "1.0542578\n",
      "0.96942604\n",
      "0.9767761\n",
      "1.3856034\n",
      "1.0380825\n",
      "1.085679\n",
      "1.1102443\n",
      "1.0905197\n",
      "1.1449951\n",
      "0.94818383\n",
      "1.087266\n",
      "1.1443983\n",
      "0.9629737\n",
      "1.163625\n",
      "1.0838499\n",
      "1.1807356\n",
      "1.09906\n",
      "1.0301983\n",
      "1.0653907\n",
      "1.0826074\n",
      "1.0471796\n",
      "1.1537273\n",
      "1.3038518\n",
      "1.2364708\n",
      "0.9373209\n",
      "1.0027962\n",
      "1.0982685\n",
      "1.2733626\n",
      "1.1186354\n",
      "1.2154771\n",
      "0.99245834\n",
      "1.0289779\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "x = tf.placeholder(tf.float32,shape=(batchsize,image_pixels))\n",
    "y = tf.placeholder(tf.float32, shape=(batchsize,10))\n",
    "\n",
    "hidden_1 = tf.nn.relu(tf.matmul(x,cre_weights([image_pixels,100]))+cre_biases([100]))\n",
    "print(hidden_1)\n",
    "logits = tf.nn.relu(tf.matmul(hidden_1,cre_weights([100,10])+cre_biases([10])))\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y,name = 'xentropy')\n",
    "loss = tf.reduce_mean(cross_entropy,name='xentropy_mean') \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for step in range(10000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        l ,_=sess.run([loss,train_op],feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if (step+1)%100==0:\n",
    "            print(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
